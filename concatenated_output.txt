# agent.py
from smolagents import ToolCallingAgent, LiteLLMModel, DuckDuckGoSearchTool
from tools import extract_books, recommend_similar_books

# Local Llama3 via Ollama
model = LiteLLMModel(
    model_id="ollama/llama3",
    api_base="http://localhost:11434"
)

agent = ToolCallingAgent(
    tools=[extract_books, DuckDuckGoSearchTool(), recommend_similar_books],
    model=model,
    stream_outputs=True,   # optional real-time output
)
----------------------------------------

# app.py
import gradio as gr
from agent import agent

def chat_with_agent(user_input, chat_history):
    response = agent.run(user_input)
    chat_history.append((user_input, response))
    return chat_history, chat_history

with gr.Blocks() as demo:
    gr.Markdown("## ðŸ“š Book Recommendation Agent (powered by LLaMA3 + smolagents)")
    chatbot = gr.Chatbot()
    msg = gr.Textbox(placeholder="Tell me a few books you like...", label="Your favorite books")
    submit = gr.Button("Submit")  # Create a submit button
    clear = gr.Button("Clear")

    # Connect the submit button to the chat_with_agent function
    submit.click(chat_with_agent, [msg, chatbot], [chatbot, chatbot])
    
    # Keep the existing functionality for the Enter key
    msg.submit(chat_with_agent, [msg, chatbot], [chatbot, chatbot])
    
    clear.click(lambda: ([], ""), None, [chatbot, msg])

demo.launch()

----------------------------------------

# concatenate_py_files.py
import os

def concatenate_py_files(output_file):
    # Get the current directory
    current_directory = os.getcwd()
    
    # List all .py files in the current directory
    py_files = [f for f in os.listdir(current_directory) if f.endswith('.py')]
    
    with open(output_file, 'w', encoding='utf-8') as outfile:
        for py_file in py_files:
            # Write the file name as a header
            outfile.write(f"# {py_file}\n")
            # Write the content of the file
            with open(py_file, 'r', encoding='utf-8') as infile:
                outfile.write(infile.read())
            # Add a separator line
            outfile.write("\n" + "-"*40 + "\n\n")

if __name__ == "__main__":
    output_file_name = "concatenated_output.txt"
    concatenate_py_files(output_file_name)
    print(f"All .py files have been concatenated into {output_file_name}.")

----------------------------------------

# tools.py
from smolagents.tools import tool
import re
import requests
import logging
from bs4 import BeautifulSoup

def duckduckgo_search_snippets(query: str, max_snippets: int = 3) -> list:
    """
    Performs a DuckDuckGo search and extracts text snippets from the results.
    """
    logging.debug(f"[duckduckgo_search_snippets] Query: {query}")
    try:
        resp = requests.get("https://lite.duckduckgo.com/lite/", params={"q": query}, timeout=10)
        if not resp.ok:
            return [f"[Error] Search failed for query: {query}"]

        soup = BeautifulSoup(resp.text, "html.parser")
        results = soup.find_all("a", class_="result-link")[:max_snippets]
        snippets = []

        for link in results:
            snippet = link.get_text(strip=True)
            if snippet:
                snippets.append(snippet)

        return snippets or ["[No results found]"]
    except Exception as e:
        logging.error(f"[duckduckgo_search_snippets] Failed: {e}")
        return [f"Search error: {e}"]

@tool
def extract_books(text: str) -> list:
    """
    Use LLM reasoning to extract a list of books from the user's input.

    Args:
        text: Free-form user input describing books they liked.

    Returns:
        A list of dictionaries, each with keys:
            - 'title': the title of the book
            - 'author': the author of the book (if known)
    """
    # Weâ€™ll delegate extraction to the LLM itself.
    # This is just a placeholder tool schema, the model will generate the response
    return []

@tool
def search_web(query: str) -> str:
    """
    Perform a web search for information about books, authors, or topics.

    Args:
        query (str): The search query to look up.

    Returns:
        str: A text snippet or summary from the search results.
    """
    logging.debug(f"[search_web] Searching: {query}")
    try:
        resp = requests.get("https://lite.duckduckgo.com/lite/", params={"q": query}, timeout=10)
        if resp.ok:
            return resp.text[:1000]
    except Exception as e:
        logging.error(f"[search_web] Failed: {e}")
        return f"Search error: {e}"

@tool
def recommend_similar_books(book_list: list) -> list:
    """
    Given a list of input books (title + author), search the web and suggest other similar books.

    Args:
        book_list: A list of dicts with keys 'title' and 'author'.

    Returns:
        A list of recommendations, each a dict with:
            - 'title': recommended book's title
            - 'author': author (if known)
            - 'reason': why it was recommended
    """
    from smolagents import call_llm  # ensure this is imported for calling your LLM

    all_snippets = ""
    for book in book_list:
        query = f"Books similar to '{book['title']}' by {book.get('author', 'unknown author')}"
        snippets = duckduckgo_search_snippets(query)
        all_snippets += f"### Search results for {book['title']}:\n" + "\n".join(snippets) + "\n\n"

    # Now ask the LLM to analyze snippets and generate recommendations
    prompt = f"""You are a book recommendation assistant.

Here are search results for books similar to some user favorites:

{all_snippets}

Based on these, recommend 3 books. For each, include:
- title
- author (if known)
- reason for recommendation (based on search result info)

Return as a list of JSON objects.
"""
    response = call_llm(prompt, model="ollama/llama3", api_base="http://localhost:11434")

    try:
        # Try to parse list of dicts from response (defensive parsing)
        import json
        recommendations = json.loads(response)
        if isinstance(recommendations, list):
            return recommendations
    except Exception as e:
        logging.error(f"Failed to parse LLM response: {e}")

    return [{"title": "Unknown", "author": "Unknown", "reason": "Failed to parse LLM output."}]

----------------------------------------

