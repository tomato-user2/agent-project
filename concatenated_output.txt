# agents.py
from langgraph.graph import StateGraph, END
from search import duckduckgo_search
import ollama
import asyncio
import json

# Node 1: Extract books from user input
async def extract_books_node(state):
    user_input = state.get("user_input", "")
    prompt = (
        f"Extract all book titles and authors from the following text. "
        "If an author is missing, fill it in using your knowledge. "
        "Output as a JSON list of dicts like this: "
        "[{{'title': '...', 'author': '...'}}, ...].\n\n"
        f"User input: {user_input}"
    )
    response = ollama.chat(model="llama3", messages=[{"role": "user", "content": prompt}])

    try:
        books = json.loads(response['message']['content'])
    except Exception:
        books = []

    return {"extracted_books": books}

# Node 2: Recommend similar books using DuckDuckGo search
async def recommend_books_node(state):
    extracted_books = state.get("extracted_books", [])
    reasoning_steps = []
    recommended_books = []

    if not extracted_books:
        reasoning_steps.append("No books extracted from the input. Check if the extraction failed.")
        return {"recommendations": [], "reasoning": "\n".join(reasoning_steps)}

    for book in extracted_books:
        query = f"Books similar to '{book['title']}' by {book['author']}"
        reasoning_steps.append(f"Searching DuckDuckGo with query: {query}")
        search_results = await duckduckgo_search(query)

        if not search_results:
            reasoning_steps.append(f"No results found for: {query}")
            continue

        for res in search_results:
            recommended_books.append({
                "title": res["title"],
                "link": res["link"],
                "snippet": res["snippet"]
            })
            reasoning_steps.append(f"‚úÖ Found: {res['title']} ({res['link']})")

    if not recommended_books:
        reasoning_steps.append("No recommendations found across all queries.")

    return {
        "recommendations": recommended_books,
        "reasoning": "\n".join(reasoning_steps)
    }

# Build the graph
def build_graph():
    graph = StateGraph(dict)

    graph.add_node("extract_books", extract_books_node)
    graph.add_node("recommend_books", recommend_books_node)

    graph.add_edge("extract_books", "recommend_books")
    graph.add_edge("recommend_books", END)

    graph.set_entry_point("extract_books")
    return graph.compile()

----------------------------------------

# app.py
import gradio as gr
from agents import build_graph
import asyncio

# Build the LangGraph once
graph = build_graph()

async def run_book_recommender(user_input):
    initial_state = {"user_input": user_input}

    # Consume the generator until completion
    async for state in graph.astream(initial_state):
        final_state = state  # This keeps updating with each step

    recommendations = final_state.get("recommendations", [])
    reasoning = final_state.get("reasoning", "")

    recommendations_text = "\n\n".join(
        [f"üìò {rec['title']}\nüîó {rec['link']}\nüìù {rec['snippet']}" for rec in recommendations]
    ) or "No recommendations found."

    return recommendations_text, reasoning

# Gradio UI
with gr.Blocks() as demo:
    gr.Markdown("# üìö AI Book Recommender")
    user_input = gr.Textbox(label="Tell me some books you like")
    recommend_btn = gr.Button("Get Recommendations")
    recommendations_output = gr.Textbox(label="Recommended Books")
    reasoning_output = gr.Textbox(label="Reasoning Steps")

    recommend_btn.click(run_book_recommender, inputs=user_input, outputs=[recommendations_output, reasoning_output])

if __name__ == "__main__":
    demo.launch()

----------------------------------------

# concatenate_py_files.py
import os

def concatenate_py_files(output_file):
    # Get the current directory
    current_directory = os.getcwd()
    
    # List all .py files in the current directory
    py_files = [f for f in os.listdir(current_directory) if f.endswith('.py')]
    
    with open(output_file, 'w', encoding='utf-8') as outfile:
        for py_file in py_files:
            # Write the file name as a header
            outfile.write(f"# {py_file}\n")
            # Write the content of the file
            with open(py_file, 'r', encoding='utf-8') as infile:
                outfile.write(infile.read())
            # Add a separator line
            outfile.write("\n" + "-"*40 + "\n\n")

if __name__ == "__main__":
    output_file_name = "concatenated_output.txt"
    concatenate_py_files(output_file_name)
    print(f"All .py files have been concatenated into {output_file_name}.")

----------------------------------------

# search.py
import httpx
from selectolax.parser import HTMLParser

async def duckduckgo_search(query, max_results=5):
    url = f"https://html.duckduckgo.com/html/?q={query}"
    headers = {"User-Agent": "Mozilla/5.0"}
    async with httpx.AsyncClient() as client:
        response = await client.get(url, headers=headers, timeout=10)
    html = HTMLParser(response.text)
    results = []
    # DuckDuckGo uses div.result for each result block
    for result in html.css("div.result")[:max_results]:
        title_el = result.css_first("a.result__a")
        snippet_el = result.css_first(".result__snippet")
        if title_el and snippet_el:
            title = title_el.text(strip=True)
            link = title_el.attributes.get("href", "")
            snippet = snippet_el.text(strip=True)
            results.append({"title": title, "link": link, "snippet": snippet})
    return results

----------------------------------------

